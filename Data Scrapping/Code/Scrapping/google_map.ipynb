{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Google Map Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data\"\n",
    "search_queries = [\n",
    "    \"https://www.google.com/maps/search/%D1%88%D0%BA%D0%BE%D0%BB%D0%B0+%D0%B2+%D1%82%D0%B0%D1%88%D0%BA%D0%B5%D0%BD%D1%82%D0%B5/@41.3113397,69.251939,15z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/maktab+%D0%B2+%D1%82%D0%B0%D1%88%D0%BA%D0%B5%D0%BD%D1%82/@41.3113025,69.2210391,13z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/school+%D0%B2+%D1%82%D0%B0%D1%88%D0%BA%D0%B5%D0%BD%D1%82/@41.3112731,69.221039,13z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/%D0%BF%D0%B0%D1%80%D0%BA%D0%B8+/@41.3113172,69.2210391,13z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/korzinka/@41.3112584,69.221039,13z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/havas/@41.3112438,69.221039,13z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/baraka/@41.3112291,69.221039,13z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/%D0%BF%D0%B0%D1%80%D0%BA+%D0%B2+%D1%82%D0%B0%D1%88%D0%BA%D0%B5%D0%BD%D1%82%D0%B5/@41.3300434,69.258444,12z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/%D0%B1%D0%B0%D0%B7%D0%B0%D1%80/@41.3301021,69.2584441,12z/data=!3m1!4b1?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/bolalar+bogchasi/@41.2960354,69.1294528,10.25z?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/%D1%81%D1%82%D0%B0%D0%BD%D1%86%D0%B8%D1%8F+%D0%BC%D0%B5%D1%82%D1%80%D0%BE/@41.2935533,69.2620823,13.5z?entry=ttu\",\n",
    "    \"https://www.google.com/maps/search/%D0%B4%D0%B5%D1%82%D1%81%D0%BA%D0%B8%D0%B9+%D1%81%D0%B0%D0%B4+%D0%B2+%D1%82%D0%B0%D1%88%D0%BA%D0%B5%D0%BD%D1%82%D0%B5/@41.2950951,69.129451,10z?entry=ttu\"\n",
    "]\n",
    "\n",
    "record = []\n",
    "e = []\n",
    "le = 0\n",
    "\n",
    "def google_map_extractor(query):\n",
    "    link = f\"{query}&hl=ru\"\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(link)\n",
    "    time.sleep(5)\n",
    "    action = ActionChains(browser)\n",
    "    a = browser.find_elements(By.CLASS_NAME, \"hfpxzc\")\n",
    "    \n",
    "    while len(a) < 1000:\n",
    "        var = len(a)\n",
    "        scroll_origin = ScrollOrigin.from_element(a[0])\n",
    "        action.scroll_from_origin(scroll_origin, 0, 20000).perform()\n",
    "        time.sleep(3)\n",
    "        a = browser.find_elements(By.CLASS_NAME, \"hfpxzc\")\n",
    "\n",
    "        if len(a) == var:\n",
    "            le+=1\n",
    "            if le > 2:\n",
    "                break\n",
    "        else:\n",
    "            le = 0    \n",
    "\n",
    "\n",
    "    browser.implicitly_wait(10)\n",
    "    html_content = browser.page_source\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    div_elements = soup.find_all('div', class_=re.compile(r'^Nv2PK '))\n",
    "\n",
    "    for div_element in div_elements:\n",
    "        name = div_element.find('a', class_='hfpxzc')['aria-label']\n",
    "        category_parent_divs = div_element.find_all('div', class_='W4Efsd')\n",
    "        if len(category_parent_divs) >= 2:\n",
    "            category_span =category_parent_divs[1].select('span > span')\n",
    "            category = category_span[0].text.strip()\n",
    "        else:\n",
    "            category = ''\n",
    "        href = div_element.find('a', class_='hfpxzc')['href']\n",
    "        latitude = re.search(r'!3d(.*?)!4d(.*?)!', href).group(1)\n",
    "        longitude = re.search(r'!3d(.*?)!4d(.*?)!', href).group(2)\n",
    "        if name not in record:\n",
    "            record.append((name,category,latitude,longitude))\n",
    " \n",
    "\n",
    "for query in search_queries:\n",
    "    print(query)\n",
    "    google_map_extractor(query)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(record, columns=['name', 'category', 'lat', 'long'])\n",
    "file_name = '../Data/Map_Data.xlsx'\n",
    "df.to_excel(file_name, index=False)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/didi/Desktop/data_scrapping/Data Scrapping/Data/Map_Data.xlsx')\n",
    "categories_to_keep = ['Школа', 'Супермаркет', 'Магазин', 'Частная школа', 'Средняя школа', 'Начальная школа',\n",
    "                      'Международная школа', 'Торговый центр', 'Продовольственный магазин',\n",
    "                      'Магазин шаговой доступности', 'Супермаркет низких цен', 'Ресторан', 'фастфуд',\n",
    "                      'Узбекская кухня','Кафе','Суши','Турецкая кухня','Гамбургеры','Корейская кухня','Японская кухня','Еда на вынос','Доставка готовой еды','Парк',  'Станция метро',  'Детский сад']\n",
    "\n",
    "df = df[df['category'].isin(categories_to_keep)]\n",
    "\n",
    "corrections = {\n",
    "    'Магазин': 'grocery',\n",
    "    'Супермаркет': 'grocery',\n",
    "    'Продовольственный магазин': 'grocery',\n",
    "    'Магазин шаговой доступности': 'grocery',\n",
    "    'Супермаркет низких цен': 'grocery',\n",
    "    'Рынок': 'grocery',\n",
    "    'Начальная школа': 'school',\n",
    "    'Частная школа': 'school',\n",
    "    'Средняя школа': 'school',\n",
    "    'Школа': 'school',\n",
    "    'Международная школа': 'school',\n",
    "    'Торговый центр': 'mall',\n",
    "    'Парк': 'park',\n",
    "    'Парк': 'park',\n",
    "    'Станция метро': 'metro_station',\n",
    "    'Детский сад': 'kindergarten'\n",
    "}\n",
    "\n",
    "df['category'] = df['category'].replace(corrections)\n",
    "\n",
    "df.dropna(subset=['category', 'lat', 'long'], inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=['category', 'lat', 'long'], inplace=True)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### School and Kindergarten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_school_df = df[(df['category'] != 'school') & (df['category'] != 'kindergarten')].copy()\n",
    "not_school_df['name'] = not_school_df['name'].str.lower()\n",
    "school_with_numbers_df = df[(df['category'] == 'school') & df['name'].str.contains('\\d')].copy()\n",
    "school_with_numbers_df['name'] = school_with_numbers_df['name'].str.extract('(\\d+)')\n",
    "\n",
    "kindergartens_with_numbers_df = df[(df['category'] == 'kindergarten') & df['name'].str.contains('\\d')].copy()\n",
    "kindergartens_with_numbers_df['name'] = kindergartens_with_numbers_df['name'].str.extract('(\\d+)')\n",
    "\n",
    "df = pd.concat([not_school_df, school_with_numbers_df, kindergartens_with_numbers_df])\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grogeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['category'] == 'grocery') & df['name'].str.lower().str.contains('havas', case=False, na=False),\n",
    "    (df['category'] == 'grocery') & df['name'].str.lower().str.contains('korzinka', case=False, na=False),\n",
    "    (df['category'] == 'grocery') & df['name'].str.lower().str.contains('baraka', case=False, na=False),\n",
    "    (df['category'] == 'grocery') & ~(df['name'].str.lower().str.contains('havas', case=False, na=False) |\n",
    "    df['name'].str.lower().str.contains('korzinka', case=False, na=False) |\n",
    "    df['name'].str.lower().str.contains('baraka', case=False, na=False)),\n",
    "]\n",
    "choices = ['havas', 'korzinka', 'baraka', None]\n",
    "df['name'] = np.select(conditions, choices, default=df['name'])\n",
    "df = df[~df['name'].isna()]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_park = df['name'].str.lower().str.contains('парк', na=False)\n",
    "df.loc[contains_park, 'name'] = df.loc[contains_park, 'name'].str.replace('парк', '', case=False)\n",
    "df['name'] = df['name'].str.strip()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['name'], inplace=True)\n",
    "df = df[df['name'] != '']\n",
    "df.drop_duplicates(subset=['name', 'category', 'lat', 'long'], inplace=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../Data/Cleaned_Map_Data.xlsx'\n",
    "df.to_excel(file_name, index=False)\n",
    "\n",
    "\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}