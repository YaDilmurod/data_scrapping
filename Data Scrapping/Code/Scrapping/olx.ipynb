{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_to_check = [\n",
    "                            'Алмазарский район',\n",
    "                            'Бектемирский район',\n",
    "                            'Мирабадский район',\n",
    "                            'Мирзо-Улугбекский район',\n",
    "                            'Сергелийский район',\n",
    "                            'Учтепинский район',\n",
    "                            'Чиланзарский район',\n",
    "                            'Шайхантахурский район',\n",
    "                            'Юнусабадский район',\n",
    "                            'Яккасарайский район',\n",
    "                            'Яшнабадский район',\n",
    "                            'Янгихаётский район'\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ReadTimeout, RequestException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Function to convert the date string to the desired format\n",
    "def convert_date_format(input_date):\n",
    "    # Check if the date is \"Сегодня в hh:mm\"\n",
    "    if \"Сегодня\" in input_date:\n",
    "        current_date = datetime.now().strftime(\"%d.%m.%Y\")\n",
    "        formatted_date = f\"{current_date}\"\n",
    "    else:\n",
    "        month_dict = {\n",
    "            'января': '01', 'февраля': '02', 'марта': '03',\n",
    "            'апреля': '04', 'мая': '05', 'июня': '06',\n",
    "            'июля': '07', 'августа': '08', 'сентября': '09',\n",
    "            'октября': '10', 'ноября': '11', 'декабря': '12'\n",
    "        }\n",
    "        for ru_month, num_month in month_dict.items():\n",
    "            input_date = input_date.replace(ru_month, num_month)\n",
    "\n",
    "        formatted_date = datetime.strptime(input_date, \"%d %m %Y г.\").strftime(\"%d.%m.%Y\")[:10]\n",
    "\n",
    "    return pd.to_datetime(formatted_date, format=\"%d.%m.%Y\")\n",
    "\n",
    "def scrape_apartment_details(main_url, num_pages):\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        for page in range(1, num_pages):\n",
    "            current_url = f\"{main_url}?page={page}\"\n",
    "            print(main_url, page)\n",
    "            try:\n",
    "                response = requests.get(current_url, timeout=5)\n",
    "                response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Find all apartment links inside the specified div\n",
    "                apartment_links = soup.select('div.css-u2ayx9 a')\n",
    "                regions = soup.select('div.css-odp1qd > p.css-1a4brun')\n",
    "                # Loop through each apartment link\n",
    "                for link, region in zip(apartment_links, regions):\n",
    "                    apartment_url = urljoin(main_url, link['href'])\n",
    "                    apartment_response = requests.get(apartment_url)\n",
    "                    if apartment_response.status_code == 200:\n",
    "                        apartment_soup = BeautifulSoup(apartment_response.text, 'html.parser')\n",
    "\n",
    "                        # Extract the information from the detailed page\n",
    "                        title_element = apartment_soup.find('h4', class_='css-1juynto')\n",
    "\n",
    "                        region_text = region.text.strip()\n",
    "                        for district in districts_to_check:\n",
    "                            if district in region_text:\n",
    "                                region = district\n",
    "                                break\n",
    "\n",
    "                        if title_element:\n",
    "                            apartment_title = title_element.text.strip()\n",
    "\n",
    "                            # Find the price container element in the detailed apartment page\n",
    "                            price_container_element = apartment_soup.find('div', {'data-testid': 'ad-price-container'})\n",
    "\n",
    "                            if price_container_element:\n",
    "                                # Find the h3 element within the price container\n",
    "                                price_element = price_container_element.find('h3')\n",
    "\n",
    "                                # Extract and print the text content of the h3 element\n",
    "                                apartment_price = price_element.text.strip() if price_element else None\n",
    "\n",
    "                                # Extract currency and numeric part\n",
    "                                currency = 'UZS' if 'сум' in apartment_price else 'USD'\n",
    "                                numeric_part = ''.join(filter(str.isdigit, apartment_price))\n",
    "\n",
    "                            # Extract negotiability\n",
    "                            negotiable_element = apartment_soup.find('div', {'data-testid': 'ad-price-container'})\n",
    "\n",
    "                            if negotiable_element:\n",
    "                                negotiable_element = negotiable_element.find('p')\n",
    "                                negotiable = 'Yes' if negotiable_element and 'Договорная' in negotiable_element.text else 'No'\n",
    "                            else:\n",
    "                                negotiable = 'No'\n",
    "\n",
    "                            # Extract description from div with data-cy=\"ad_description\"\n",
    "                            description_element = apartment_soup.find('div', {'data-cy': 'ad_description'})\n",
    "                            apartment_description = description_element.text.strip() if description_element else None\n",
    "\n",
    "                            # Extract additional information with handling if element doesn't exist\n",
    "                            details_element = apartment_soup.select_one('ul.css-sfcl1s')\n",
    "                            details = {}\n",
    "\n",
    "                            if details_element:\n",
    "                                for li in details_element.find_all('li'):\n",
    "                                    li_text = li.text.strip()\n",
    "                                    if ':' in li_text:\n",
    "                                        column_name, content = li_text.split(':', 1)\n",
    "                                        details[column_name.strip()] = content.strip()\n",
    "\n",
    "                            # Extract date from span with data-cy=\"ad-posted-at\"\n",
    "                            date_element = apartment_soup.find('span', {'data-cy': 'ad-posted-at'})\n",
    "                            posted_at = date_element.text.strip() if date_element else None\n",
    "\n",
    "                            # Use the function to convert the date\n",
    "                            posted_at = convert_date_format(posted_at)\n",
    "\n",
    "                            result_entry = {\n",
    "                                'Название': apartment_title,\n",
    "                                'Валюта': currency,\n",
    "                                'Цена': numeric_part,\n",
    "                                'Цена_договорная': negotiable,\n",
    "                                'Описание': apartment_description[8:],\n",
    "                                'Дата': posted_at,\n",
    "                                'Район': region,\n",
    "                                **details\n",
    "                            }\n",
    "                            results.append(result_entry)\n",
    "                            print(apartment_url)\n",
    "\n",
    "                    else:\n",
    "                        print(f\"Failed to retrieve details from link: {apartment_url}. Status code: {apartment_response.status_code}\")\n",
    "\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"ReadTimeout exception: {e}. Moving to the next iteration.\")\n",
    "                time.sleep(5)  # Add a delay before retrying, adjust as needed\n",
    "                continue  # Move to the next iteration of the loop\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"RequestException: {e}\")\n",
    "                # Handle other request exceptions if needed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Create a DataFrame from the results list\n",
    "        final_df = pd.DataFrame(results)\n",
    "        return final_df\n",
    "\n",
    "main_url = \"https://www.olx.uz/nedvizhimost/kvartiry/prodazha/tashkent/\"\n",
    "kvartiri_df = scrape_apartment_details(main_url, num_pages=30)\n",
    "kvartiri_df[\"Тип\"] = 'Квартира'\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ReadTimeout, RequestException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Function to convert the date string to the desired format\n",
    "def convert_date_format(input_date):\n",
    "    # Check if the date is \"Сегодня в hh:mm\"\n",
    "    if \"Сегодня\" in input_date:\n",
    "        current_date = datetime.now().strftime(\"%d.%m.%Y\")\n",
    "        formatted_date = f\"{current_date}\"\n",
    "    else:\n",
    "        month_dict = {\n",
    "            'января': '01', 'февраля': '02', 'марта': '03',\n",
    "            'апреля': '04', 'мая': '05', 'июня': '06',\n",
    "            'июля': '07', 'августа': '08', 'сентября': '09',\n",
    "            'октября': '10', 'ноября': '11', 'декабря': '12'\n",
    "        }\n",
    "        for ru_month, num_month in month_dict.items():\n",
    "            input_date = input_date.replace(ru_month, num_month)\n",
    "\n",
    "        formatted_date = datetime.strptime(input_date, \"%d %m %Y г.\").strftime(\"%d.%m.%Y\")[:10]\n",
    "\n",
    "    return pd.to_datetime(formatted_date, format=\"%d.%m.%Y\")\n",
    "\n",
    "def scrape_apartment_details(main_url, num_pages):\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        for page in range(1, num_pages):\n",
    "            current_url = f\"{main_url}?page={page}\"\n",
    "\n",
    "            try:\n",
    "                response = requests.get(current_url, timeout=5)\n",
    "                response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Find all apartment links inside the specified div\n",
    "                apartment_links = soup.select('div.css-u2ayx9 a')\n",
    "                regions = soup.select('div.css-odp1qd > p.css-1a4brun')\n",
    "\n",
    "                # Loop through each apartment link\n",
    "                for link, region in zip(apartment_links, regions):\n",
    "                    apartment_url = urljoin(main_url, link['href'])\n",
    "                    apartment_response = requests.get(apartment_url)\n",
    "                    if apartment_response.status_code == 200:\n",
    "                        apartment_soup = BeautifulSoup(apartment_response.text, 'html.parser')\n",
    "\n",
    "                        # Extract the information from the detailed page\n",
    "                        title_element = apartment_soup.find('h4', class_='css-1juynto')\n",
    "\n",
    "                        region_text = region.text.strip()\n",
    "                        for district in districts_to_check:\n",
    "                            if district in region_text:\n",
    "                                region = district\n",
    "                                break\n",
    "\n",
    "                        if title_element:\n",
    "                            apartment_title = title_element.text.strip()\n",
    "\n",
    "                            # Find the price container element in the detailed apartment page\n",
    "                            price_container_element = apartment_soup.find('div', {'data-testid': 'ad-price-container'})\n",
    "\n",
    "                            if price_container_element:\n",
    "                                # Find the h3 element within the price container\n",
    "                                price_element = price_container_element.find('h3')\n",
    "\n",
    "                                # Extract and print the text content of the h3 element\n",
    "                                apartment_price = price_element.text.strip() if price_element else None\n",
    "\n",
    "                                # Extract currency and numeric part\n",
    "                                currency = 'UZS' if 'сум' in apartment_price else 'USD'\n",
    "                                numeric_part = ''.join(filter(str.isdigit, apartment_price))\n",
    "\n",
    "                            # Extract negotiability\n",
    "                            negotiable_element = apartment_soup.find('div', {'data-testid': 'ad-price-container'})\n",
    "\n",
    "                            if negotiable_element:\n",
    "                                negotiable_element = negotiable_element.find('p')\n",
    "                                negotiable = 'Yes' if negotiable_element and 'Договорная' in negotiable_element.text else 'No'\n",
    "                            else:\n",
    "                                negotiable = 'No'\n",
    "\n",
    "                            # Extract description from div with data-cy=\"ad_description\"\n",
    "                            description_element = apartment_soup.find('div', {'data-cy': 'ad_description'})\n",
    "                            apartment_description = description_element.text.strip() if description_element else None\n",
    "\n",
    "                            # Extract additional information with handling if element doesn't exist\n",
    "                            details_element = apartment_soup.select_one('ul.css-sfcl1s')\n",
    "                            details = {}\n",
    "\n",
    "                            if details_element:\n",
    "                                for li in details_element.find_all('li'):\n",
    "                                    li_text = li.text.strip()\n",
    "                                    if ':' in li_text:\n",
    "                                        column_name, content = li_text.split(':', 1)\n",
    "                                        details[column_name.strip()] = content.strip()\n",
    "\n",
    "                            # Extract date from span with data-cy=\"ad-posted-at\"\n",
    "                            date_element = apartment_soup.find('span', {'data-cy': 'ad-posted-at'})\n",
    "                            posted_at = date_element.text.strip() if date_element else None\n",
    "\n",
    "                            # Use the function to convert the date\n",
    "                            posted_at = convert_date_format(posted_at)\n",
    "\n",
    "                            result_entry = {\n",
    "                                'Название': apartment_title,\n",
    "                                'Валюта': currency,\n",
    "                                'Цена': numeric_part,\n",
    "                                'Цена_договорная': negotiable,\n",
    "                                'Описание': apartment_description[8:],\n",
    "                                'Дата': posted_at,\n",
    "                                'Район': region,\n",
    "                                **details\n",
    "                            }\n",
    "                            results.append(result_entry)\n",
    "                            print(apartment_url)\n",
    "\n",
    "                    else:\n",
    "                        print(f\"Failed to retrieve details from link: {apartment_url}. Status code: {apartment_response.status_code}\")\n",
    "\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"ReadTimeout exception: {e}. Moving to the next iteration.\")\n",
    "                time.sleep(5)  # Add a delay before retrying, adjust as needed\n",
    "                continue  # Move to the next iteration of the loop\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"RequestException: {e}\")\n",
    "                # Handle other request exceptions if needed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Create a DataFrame from the results list\n",
    "        final_df = pd.DataFrame(results)\n",
    "        return final_df\n",
    "\n",
    "main_url = \"https://www.olx.uz/nedvizhimost/doma/prodazha/tashkent/\"\n",
    "dom_df = scrape_apartment_details(main_url, num_pages=10)\n",
    "dom_df[\"Тип\"] = 'Дом'\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([dom_df, kvartiri_df], ignore_index=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Дата'] = pd.to_datetime(final_df['Дата'], format='%Y-%m-%d').dt.strftime('%d.%m.%Y')\n",
    "final_df['Общая площадь'] = final_df['Общая площадь'].str.extract('(\\d+)').astype(float)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_mapping = {\n",
    "    \"Назначение\": \"Тип\",\n",
    "    \"Тип жилья\": \"Тип постройки\",\n",
    "    \"Тип строения\": \"Материал\",\n",
    "    \"Этажность дома\": \"Этажность\",\n",
    "    \"Общая площадь\": \"Площадь\",\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "final_df.rename(columns=column_name_mapping, inplace=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\"Источник\", \"Название\", \"Тип\",\"Санузел\", \"Тип постройки\", \"Материал\", \"Широта\", \n",
    "                    \"Долгота\", \"Район\", \"Этаж\", \"Этажность\", \"Ремонт\", \"Площадь\", \n",
    "                    \"Количество комнат\", \"Дата публикации\", \"Валюта\", \"Цена\", \"Дата создания\"]\n",
    "\n",
    "# Create a new DataFrame with the specified columns\n",
    "new_df = pd.DataFrame(columns=columns_to_check)\n",
    "\n",
    "# Check if columns exist in final_df and create them with None values if not\n",
    "for column in columns_to_check:\n",
    "    if column not in final_df.columns:\n",
    "        final_df[column] = None\n",
    "        new_df[column] = None\n",
    "    else:\n",
    "        new_df[column] = final_df[column]\n",
    "\n",
    " \n",
    "new_df[\"Источник\"] = 'Olx'\n",
    "new_df[\"Район\"] = ''\n",
    "new_df[\"Дата создания\"] = datetime.now().strftime(\"%d.%m.%Y\")\n",
    "new_df[columns_to_check]\n",
    "new_df.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to check for duplicates\n",
    "columns_to_check_dup = [\"Источник\", \"Название\", \"Тип\", \"Санузел\", \"Тип постройки\", \"Материал\", \n",
    "                    \"Широта\", \"Долгота\", \"Район\", \"Этаж\", \"Этажность\", \"Ремонт\", \"Площадь\", \n",
    "                    \"Количество комнат\", \"Дата публикации\", \"Валюта\", \"Цена\"]\n",
    "\n",
    "# Count the number of rows before removing duplicates\n",
    "rows_before = new_df.shape[0]\n",
    "\n",
    "# Remove duplicates based on specified columns\n",
    "df_no_duplicates = new_df.drop_duplicates(subset=columns_to_check_dup, keep=False)\n",
    "\n",
    "# Count the number of rows after removing duplicates\n",
    "rows_after = df_no_duplicates.shape[0]\n",
    "\n",
    "# Calculate the number of rows deleted\n",
    "rows_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"\\nNumber of rows deleted: {rows_deleted}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming x is your variable and data is the data you want to store\n",
    "name_of_file = \"Olx\"\n",
    "df = pd.DataFrame(df_no_duplicates)\n",
    "\n",
    "# Set the path to the Excels folder (assuming it is a sibling of the Notebooks folder)\n",
    "excels_folder_path = os.path.join(os.path.dirname(os.getcwd()), \"Excels\")\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "if not os.path.exists(excels_folder_path):\n",
    "    os.makedirs(excels_folder_path)\n",
    "\n",
    "# Create a folder with the name_of_file only if it doesn't exist\n",
    "file_folder_path = os.path.join(excels_folder_path, name_of_file)\n",
    "\n",
    "if not os.path.exists(file_folder_path):\n",
    "    os.makedirs(file_folder_path)\n",
    "\n",
    "excel_file_name = os.path.join(file_folder_path, f\"{name_of_file}.xlsx\")\n",
    "\n",
    "# Check if the file already exists\n",
    "if os.path.exists(excel_file_name):\n",
    "    # Read the existing Excel file into a DataFrame\n",
    "    existing_df = pd.read_excel(excel_file_name)\n",
    "\n",
    "    # Append the new data to the existing DataFrame\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "    # Check for duplicates in all columns\n",
    "    duplicates_mask = updated_df.duplicated(keep=False)\n",
    "\n",
    "    # Print the number of duplicates\n",
    "    num_duplicates = duplicates_mask.sum()\n",
    "    print(f\"Number of duplicates after adding new data: {num_duplicates}\")\n",
    "\n",
    "    # If duplicates exist, remove them\n",
    "    if any(duplicates_mask):\n",
    "        updated_df = updated_df[~duplicates_mask]\n",
    "\n",
    "    # Write the updated DataFrame back to the Excel file\n",
    "    updated_df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "    print(f\"Data added to existing Excel file '{excel_file_name}' after removing duplicates.\")\n",
    "else:\n",
    "    # If the file doesn't exist, create a new Excel file with the data\n",
    "    df.to_excel(excel_file_name, index=False)\n",
    "    print(f\"Excel file '{excel_file_name}' created with new data.\")\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}