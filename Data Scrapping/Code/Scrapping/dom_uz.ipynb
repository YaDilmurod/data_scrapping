{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from requests.exceptions import ConnectTimeout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dom.uz/catalog/detail/13500\n",
      "https://dom.uz/catalog/detail/13501\n",
      "https://dom.uz/catalog/detail/13502\n",
      "https://dom.uz/catalog/detail/13503\n",
      "https://dom.uz/catalog/detail/13504\n",
      "https://dom.uz/catalog/detail/13505\n",
      "https://dom.uz/catalog/detail/13506\n",
      "https://dom.uz/catalog/detail/13507\n",
      "https://dom.uz/catalog/detail/13508\n",
      "https://dom.uz/catalog/detail/13509\n",
      "https://dom.uz/catalog/detail/13510\n",
      "https://dom.uz/catalog/detail/13511\n",
      "https://dom.uz/catalog/detail/13512\n",
      "https://dom.uz/catalog/detail/13513\n",
      "https://dom.uz/catalog/detail/13514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/didi/Desktop/data_scrapping/Data Scrapping/Code/Scrapping/dom_uz.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m stop_page_number \u001b[39m=\u001b[39m start_page_number \u001b[39m+\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m main_url_dom_uz \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://dom.uz/catalog/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m final_df \u001b[39m=\u001b[39m scrape_dom_uz_range(main_url_dom_uz, start_page_number, stop_page_number)\n",
      "\u001b[1;32m/Users/didi/Desktop/data_scrapping/Data Scrapping/Code/Scrapping/dom_uz.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m detail_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmain_url\u001b[39m}\u001b[39;00m\u001b[39mdetail/\u001b[39m\u001b[39m{\u001b[39;00mpage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mprint\u001b[39m(detail_url)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m result_entry \u001b[39m=\u001b[39m scrape_dom_uz_detail(detail_url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mif\u001b[39;00m result_entry:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(result_entry)\n",
      "\u001b[1;32m/Users/didi/Desktop/data_scrapping/Data Scrapping/Code/Scrapping/dom_uz.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m result_entry \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(detail_url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/dom_uz.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         apartment_soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1096\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1099\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1100\u001b[0m         (\n\u001b[1;32m   1101\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    612\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m    613\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def extract_currency_and_value(column_value):\n",
    "    parts = column_value.split(' у.е.')\n",
    "    currency = 'None'\n",
    "    price = 'None'\n",
    "\n",
    "    if len(parts) >= 2:\n",
    "        price = parts[-2].strip()\n",
    "        currency = 'USD'\n",
    "\n",
    "    return price, currency\n",
    "\n",
    "def extract_date(date_element):\n",
    "    date_str = date_element.text.strip()\n",
    "    date_format = \"%d.%m.%Y %H:%M:%S\"\n",
    "    date_obj = datetime.strptime(date_str, date_format)\n",
    "    return date_obj\n",
    "\n",
    "def scrape_dom_uz_detail(detail_url):\n",
    "    result_entry = {}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(detail_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            apartment_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extract the information from the detailed page\n",
    "            title_element = apartment_soup.find('div', class_='page-title')  # Adjust the class based on the website structure\n",
    "            date_element = apartment_soup.find('div', class_='date')\n",
    "\n",
    "            if title_element and date_element:\n",
    "                apartment_title = title_element.text.strip()\n",
    "                apartment_date = extract_date(date_element)\n",
    "\n",
    "                # Extract information from ul element with class table-block\n",
    "                details_element = apartment_soup.find('ul', class_='table-block')\n",
    "                details = {}\n",
    "\n",
    "                if details_element:\n",
    "                    for strong_tag, span_tag in zip(details_element.find_all('strong'), details_element.find_all('span')):\n",
    "                        column_name = strong_tag.text.strip()[:-1]\n",
    "                        column_value = span_tag.text.strip() if span_tag else 'None'\n",
    "\n",
    "                        # Special handling for the \"Цена\" column\n",
    "                        if column_name == 'Цена':\n",
    "                            price, currency = extract_currency_and_value(column_value)\n",
    "                            details['Валюта'] = currency\n",
    "                            details['Цена'] = price\n",
    "                        else:\n",
    "                            details[column_name] = column_value\n",
    "\n",
    "                # Extract latitude and longitude\n",
    "                lon_input = apartment_soup.find('input', {'name': 'YMAP_POINT_LON'})\n",
    "                lat_input = apartment_soup.find('input', {'name': 'YMAP_POINT_LAT'})\n",
    "                longitude = lon_input['value'] if lon_input else 'None'\n",
    "                latitude = lat_input['value'] if lat_input else 'None'\n",
    "                details['Долгота'] = longitude\n",
    "                details['Широта'] = latitude\n",
    "\n",
    "                # Add the information to the result entry\n",
    "                result_entry = {\n",
    "                    'Название': apartment_title,\n",
    "                    'Дата': apartment_date,\n",
    "                    **details\n",
    "                }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred while scraping {detail_url}: {e}\")\n",
    "\n",
    "    return result_entry\n",
    "\n",
    "def scrape_dom_uz_range(main_url, start_page, stop_page):\n",
    "    results = []\n",
    "\n",
    "    for page in range(start_page, stop_page + 1):\n",
    "        detail_url = f\"{main_url}detail/{page}\"\n",
    "        print(detail_url)\n",
    "        result_entry = scrape_dom_uz_detail(detail_url)\n",
    "\n",
    "        if result_entry:\n",
    "            results.append(result_entry)\n",
    "\n",
    "    # Create a DataFrame from the results list\n",
    "    final_df = pd.DataFrame(results)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Specify the range of page numbers you want to scrape\n",
    "start_page_number = 13500\n",
    "stop_page_number = start_page_number + 1000\n",
    "\n",
    "main_url_dom_uz = \"https://dom.uz/catalog/\"\n",
    "final_df = scrape_dom_uz_range(main_url_dom_uz, start_page_number, stop_page_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'Массив, улица': 'Адрес', 'Вид материала': 'Материал'})\n",
    "final_df['Площадь'] = final_df['Общая площадь, м2'].fillna(final_df['Площадь дома'])\n",
    "final_df['Цена'] = pd.to_numeric(final_df['Цена'].str.replace(' ', ''), errors='coerce')\n",
    "final_df['Количество комнат'] = pd.to_numeric(final_df['Количество комнат'].str.extract('(\\\\d+)', expand=False), errors='coerce')\n",
    "final_df[['Долгота', 'Широта']] = final_df[['Долгота', 'Широта']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "numeric_columns = ['Этаж квартиры', 'Этажность дома', 'Площадь', 'Количество соток']\n",
    "final_df[numeric_columns] = final_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "final_df = final_df.drop(['Площадь дома', 'Общая площадь, м2'],  axis=1)\n",
    "final_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Дата публикации'] = pd.to_datetime(final_df['Дата'], format='%Y-%m-%d').dt.strftime('%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_mapping = {\n",
    "    \"Название\": \"Тип\",\n",
    "    \"Тип жилья\": \"Тип постройки\",\n",
    "    \"Тип строения\": \"Материал\",\n",
    "    \"Этажность дома\": \"Этажность\",\n",
    "    \"Общая площадь\": \"Площадь\",\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "final_df.rename(columns=column_name_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\"Источник\", \"Название\", \"Тип\",\"Санузел\", \"Тип постройки\", \"Материал\", \"Широта\", \n",
    "                    \"Долгота\", \"Район\", \"Этаж\", \"Этажность\", \"Ремонт\", \"Площадь\", \n",
    "                    \"Количество комнат\", \"Дата публикации\", \"Валюта\", \"Цена\", \"Дата создания\"]\n",
    "\n",
    "# Create a new DataFrame with the specified columns\n",
    "new_df = pd.DataFrame(columns=columns_to_check)\n",
    "\n",
    "# Check if columns exist in final_df and create them with None values if not\n",
    "for column in columns_to_check:\n",
    "    if column not in final_df.columns:\n",
    "        final_df[column] = None\n",
    "        new_df[column] = None\n",
    "    else:\n",
    "        new_df[column] = final_df[column]\n",
    "\n",
    "new_df[\"Источник\"] = 'Dom_uz'\n",
    "new_df[\"Район\"] = ''\n",
    "new_df[\"Дата создания\"] = datetime.now().strftime(\"%d.%m.%Y\")\n",
    "new_df[columns_to_check]\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to check for duplicates\n",
    "columns_to_check_dup = [\"Источник\", \"Название\", \"Тип\", \"Санузел\", \"Тип постройки\", \"Материал\", \n",
    "                    \"Широта\", \"Долгота\", \"Район\", \"Этаж\", \"Этажность\", \"Ремонт\", \"Площадь\", \n",
    "                    \"Количество комнат\", \"Дата публикации\", \"Валюта\", \"Цена\"]\n",
    "\n",
    "# Count the number of rows before removing duplicates\n",
    "rows_before = new_df.shape[0]\n",
    "\n",
    "# Remove duplicates based on specified columns\n",
    "df_no_duplicates = new_df.drop_duplicates(subset=columns_to_check_dup, keep=False)\n",
    "\n",
    "# Count the number of rows after removing duplicates\n",
    "rows_after = df_no_duplicates.shape[0]\n",
    "\n",
    "# Calculate the number of rows deleted\n",
    "rows_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"\\nNumber of rows deleted: {rows_deleted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming x is your variable and data is the data you want to store\n",
    "name_of_file = \"Dom_uz\"\n",
    "df = pd.DataFrame(new_df)\n",
    "\n",
    "# Set the path to the Excels folder (assuming it is a sibling of the Notebooks folder)\n",
    "excels_folder_path = os.path.join(os.path.dirname(os.getcwd()), \"Excels\")\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "if not os.path.exists(excels_folder_path):\n",
    "    os.makedirs(excels_folder_path)\n",
    "\n",
    "# Create a folder with the name_of_file only if it doesn't exist\n",
    "file_folder_path = os.path.join(excels_folder_path, name_of_file)\n",
    "\n",
    "if not os.path.exists(file_folder_path):\n",
    "    os.makedirs(file_folder_path)\n",
    "\n",
    "excel_file_name = os.path.join(file_folder_path, f\"{name_of_file}.xlsx\")\n",
    "\n",
    "# Check if the file already exists\n",
    "if os.path.exists(excel_file_name):\n",
    "    # Read the existing Excel file into a DataFrame\n",
    "    existing_df = pd.read_excel(excel_file_name)\n",
    "\n",
    "    # Append the new data to the existing DataFrame\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "    # Check for duplicates in all columns\n",
    "    duplicates_mask = updated_df.duplicated(keep=False)\n",
    "\n",
    "    # Print the number of duplicates\n",
    "    num_duplicates = duplicates_mask.sum()\n",
    "    print(f\"Number of duplicates after adding new data: {num_duplicates}\")\n",
    "\n",
    "    # If duplicates exist, remove them\n",
    "    if any(duplicates_mask):\n",
    "        updated_df = updated_df[~duplicates_mask]\n",
    "\n",
    "    # Write the updated DataFrame back to the Excel file\n",
    "    updated_df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "    print(f\"Data added to existing Excel file '{excel_file_name}' after removing duplicates.\")\n",
    "else:\n",
    "    # If the file doesn't exist, create a new Excel file with the data\n",
    "    df.to_excel(excel_file_name, index=False)\n",
    "    print(f\"Excel file '{excel_file_name}' created with new data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
