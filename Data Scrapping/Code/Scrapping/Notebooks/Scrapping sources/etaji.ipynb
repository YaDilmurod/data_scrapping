{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pages:  78%|███████▊  | 233/300 [48:41<13:20, 11.95s/page]  "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def scrape_object_details(object_url):\n",
    "    url = \"https://tashkent.etagi.com\" + object_url\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    if response.status_code != 200:\n",
    "        return {}\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.select_one('[displayname=\"objectTitle\"]').get_text(strip=True) if soup.select_one('[displayname=\"objectTitle\"]') else \"N/A\"\n",
    "    количество_комнат = re.search(r'(\\d+)-комн', title)\n",
    "    количество_комнат = количество_комнат.group(1) if количество_комнат else \"N/A\"\n",
    "    тип = \"квартира\" if \"квартира\" in title.lower() else \"студия\" if \"студия\" in title.lower() else \"N/A\"\n",
    "    \n",
    "    валюта = \"USD\" if \"у.е.\" in (цена_str := soup.select_one('.eypL8').get_text(strip=True) if soup.select_one('.eypL8') else \"N/A\").lower() else \"UZS\"\n",
    "    цена = re.sub(r'[^\\d]', '', цена_str)\n",
    "\n",
    "    additional_details = {}\n",
    "    ul_element = soup.select_one('ul.PpfZ1')\n",
    "    if ul_element:\n",
    "        for li in ul_element.find_all('li'):\n",
    "            title = li.find('span', class_='Y65Dj').get_text(strip=True)\n",
    "            value = li.find('span', class_='XVztD').get_text(strip=True)\n",
    "            additional_details[title] = value\n",
    "\n",
    "    дата_публикации_raw = soup.select_one('.o8Cyp span').get_text(strip=True) if soup.select_one('.o8Cyp span') else \"N/A\"\n",
    "    дата_публикации_match = re.search(r'(\\d{2}\\.\\d{2}\\.\\d{2})', дата_публикации_raw)\n",
    "    дата_публикации = (дата_публикации_match.group(1)[:-2] + \"20\" + дата_публикации_match.group(1)[-2:]) if дата_публикации_match else \"N/A\"\n",
    "\n",
    "    return {\n",
    "        \"Название\": 'NA',\n",
    "        \"Тип\": тип,\n",
    "        \"Санузел\": soup.select_one('.object-params__value--bathrooms').get_text(strip=True) if soup.select_one('.object-params__value--bathrooms') else \"N/A\",\n",
    "        \"Тип постройки\": soup.select_one('.object-params__value--build-type').get_text(strip=True) if soup.select_one('.object-params__value--build-type') else \"N/A\",\n",
    "        \"Материал\": soup.select_one('.XVztD').get_text(strip=True) if soup.select_one('.XVztD') else \"N/A\",\n",
    "        \"Адрес\": soup.select_one('.mfrBs').get_text(strip=True) if soup.select_one('.mfrBs') else \"N/A\",\n",
    "        \"Ремонт\": additional_details.get('Ремонт', \"N/A\"),\n",
    "        \"Площадь\": re.sub(r'[^\\d]', '', additional_details.get('Общая площадь', \"0 м²\")),\n",
    "        \"Этаж\": additional_details.get('Этаж/Этажность', \"N/A\").split()[0],\n",
    "        \"Этажность\": additional_details.get('Этаж/Этажность', \"N/A\").split()[-1],\n",
    "        \"Количество комнат\": количество_комнат,\n",
    "        \"Дата публикации\": дата_публикации,\n",
    "        \"Валюта\": валюта,\n",
    "        \"Цена\": цена,\n",
    "        \"Описание\": soup.select_one('.tv2WS').get_text(strip=True) if soup.select_one('.tv2WS') else \"N/A\",\n",
    "    }\n",
    "\n",
    "def get_object_hrefs(page_url):\n",
    "    response = requests.get(page_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return [card['href'] for card in soup.select('a.templates-object-card__slider[href]')]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages(base_url, max_pages):\n",
    "    data = []\n",
    "    for page_num in tqdm(range(1, max_pages + 1), desc=\"Pages\", unit=\"page\"):\n",
    "        page_url = f\"{base_url}?page={page_num}\"\n",
    "        hrefs = get_object_hrefs(page_url)\n",
    "        \n",
    "        for href in tqdm(hrefs, desc=\"Objects\", unit=\"object\", leave=False):\n",
    "            data.append(scrape_object_details(href))\n",
    "        \n",
    "        time.sleep(2)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "base_url = \"https://tashkent.etagi.com/realty/\"\n",
    "df = scrape_all_pages(base_url, max_pages=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting coordinates for: Ташкент, улица Ниёзов 5\n",
      "Best match: \n",
      "5-Maktab улица Абдулла Кадыри, Ташкент (Cosine Similarity: 0.20)\n",
      "No matching suggestion for Ташкент, улица Ниёзов 5. Skipping.\n",
      "Getting coordinates for: Ташкент, проспект Мустакиллик 10\n",
      "Best match: \n",
      "проспект Мустакиллик 10 Ташкент (Cosine Similarity: 1.00)\n",
      "                              Адрес      Широта     Долгота\n",
      "0           Ташкент, улица Ниёзов 5         N/A         N/A\n",
      "1  Ташкент, проспект Мустакиллик 10  41.3193568  69.2958078\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize WebDriver (open it once and reuse it)\n",
    "def init_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.google.com/maps\")\n",
    "    return driver\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(input_address, suggestion_texts):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([input_address] + suggestion_texts)\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    # Compute the cosine similarity between the input address and each suggestion\n",
    "    input_vector = vectors[0]\n",
    "    suggestion_vectors = vectors[1:]\n",
    "    similarity_scores = cosine_similarity([input_vector], suggestion_vectors).flatten()\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "# Function to find the most similar search suggestion\n",
    "def select_most_similar_suggestion(driver, input_address):\n",
    "    try:\n",
    "        suggestions_elements = driver.find_elements(By.CSS_SELECTOR, 'div[jsaction=\"suggestion.select\"]')\n",
    "        suggestions_texts = [suggestion.text for suggestion in suggestions_elements]\n",
    "\n",
    "        if not suggestions_texts:\n",
    "            return False  # No suggestions available\n",
    "\n",
    "        # Calculate cosine similarity between the input address and all suggestions\n",
    "        similarity_scores = calculate_cosine_similarity(input_address, suggestions_texts)\n",
    "        \n",
    "        # Find the suggestion with the highest similarity\n",
    "        best_match_index = np.argmax(similarity_scores)\n",
    "        best_similarity_score = similarity_scores[best_match_index]\n",
    "\n",
    "        print(f\"Best match: {suggestions_texts[best_match_index]} (Cosine Similarity: {best_similarity_score:.2f})\")\n",
    "        \n",
    "        # Only select if it's 95% or more similar\n",
    "        if best_similarity_score >= 0.95:\n",
    "            suggestions_elements[best_match_index].click()\n",
    "            return True\n",
    "\n",
    "        return False  # No suitable suggestion found\n",
    "    except Exception as e:\n",
    "        print(f\"Error selecting the suggestion: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_lat_long(driver, address):\n",
    "    try:\n",
    "        # Find the search box and input the address\n",
    "        search_box = driver.find_element(By.NAME, \"q\")\n",
    "        search_box.clear()  # Clear previous input before entering new address\n",
    "        search_box.send_keys(address)\n",
    "        search_box.submit()\n",
    "        time.sleep(5)  # Wait for the search results to load\n",
    "\n",
    "        # Select the most similar suggestion based on cosine similarity\n",
    "        if not select_most_similar_suggestion(driver, address):\n",
    "            print(f\"No matching suggestion for {address}. Skipping.\")\n",
    "            return \"N/A\", \"N/A\"\n",
    "\n",
    "        time.sleep(5)  # Wait for the page to load with the selected location\n",
    "\n",
    "        # Extract latitude and longitude from the opened page itself\n",
    "        url = driver.current_url\n",
    "\n",
    "        # Parsing the latitude and longitude from the URL using 'll' or 'query'\n",
    "        if \"@\" in url:\n",
    "            coords_section = url.split(\"@\")[1].split(\",\")  # The coordinates are usually after the '@' in the URL\n",
    "            latitude = coords_section[0]\n",
    "            longitude = coords_section[1]\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return \"N/A\", \"N/A\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving coordinates for {address}: {e}\")\n",
    "        return \"N/A\", \"N/A\"\n",
    "\n",
    "# Main function to apply the extraction to the DataFrame\n",
    "def extract_lat_long_from_df(df, driver):\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "\n",
    "    for address in df['Адрес']:\n",
    "        print(f\"Getting coordinates for: {address}\")\n",
    "        latitude, longitude = get_lat_long(driver, address)\n",
    "        latitudes.append(latitude)\n",
    "        longitudes.append(longitude)\n",
    "        time.sleep(1)  # Optional: delay between requests to avoid being blocked\n",
    "    \n",
    "    df['Широта'] = latitudes\n",
    "    df['Долгота'] = longitudes\n",
    "    return df\n",
    "\n",
    "# Initialize the driver once\n",
    "driver = init_driver()\n",
    "\n",
    "# Extract latitude and longitude\n",
    "df = extract_lat_long_from_df(df, driver)\n",
    "df\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
