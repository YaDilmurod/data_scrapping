{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19753, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"../../../Data/Combined.xlsx\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[df['Цена'] != 0]\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_translation = {\n",
    "    'Источник': 'source',\n",
    "    'Название': 'title',\n",
    "    'Тип': 'type',\n",
    "    'Санузел': 'bathroom',\n",
    "    'Тип постройки': 'building_type',\n",
    "    'Материал': 'material',\n",
    "    'Широта': 'lat',\n",
    "    'Долгота': 'long',\n",
    "    'Район': 'district',\n",
    "    'Этаж': 'floor',\n",
    "    'Этажность': 'num_of_floors',\n",
    "    'Ремонт': 'renovation',\n",
    "    'Площадь': 'area',\n",
    "    'Количество комнат': 'num_of_rooms',\n",
    "    'Дата публикации': 'publication_date',\n",
    "    'Валюта': 'currency',\n",
    "    'Цена': 'price',\n",
    "    'Дата создания': 'created_date'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_translation)\n",
    "\n",
    "df = df[['source', 'type', 'building_type',\n",
    "       'lat', 'long', 'district', 'floor', 'num_of_floors', 'renovation',\n",
    "       'area', 'num_of_rooms', 'publication_date', 'currency', 'price']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates removed: 9979\n"
     ]
    }
   ],
   "source": [
    "init_len = len(df)\n",
    "\n",
    "subset_columns = ['type', 'building_type', 'district', 'floor', 'num_of_floors', 'renovation',\n",
    "         'area', 'num_of_rooms']\n",
    "\n",
    "df = df.drop_duplicates(subset=subset_columns)\n",
    "\n",
    "after_len = len(df)\n",
    "print(\"Number of duplicates removed:\", init_len - after_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd_mask = df['currency'] == \"USD\"\n",
    "df.loc[usd_mask, 'price'] *= 12500\n",
    "df.loc[usd_mask, 'currency'] = \"UZS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publication_date'] = pd.to_datetime(df['publication_date'], format='%d.%m.%Y')\n",
    "df['year'] = df['publication_date'].dt.year\n",
    "df['year'] = df['year'].fillna(np.nan).astype(float).astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['source', 'type', 'building_type',\n",
    "       'lat', 'long', 'district', 'floor', 'num_of_floors', 'renovation',\n",
    "       'area', 'num_of_rooms', 'currency', 'price', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "Data Scrapping/Data/district_borders.json: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: Data Scrapping/Data/district_borders.json: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/didi/Desktop/data_scrapping/Data Scrapping/Code/Scrapping/Notebooks/eda.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/Notebooks/eda.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m district_borders \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(\u001b[39m'\u001b[39m\u001b[39mData Scrapping/Data/district_borders.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/Notebooks/eda.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: Point(row[\u001b[39m'\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/didi/Desktop/data_scrapping/Data%20Scrapping/Code/Scrapping/Notebooks/eda.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gdf \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mGeoDataFrame(df, geometry\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/io/file.py:289\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         path_or_bytes \u001b[39m=\u001b[39m filename\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_fiona(\n\u001b[1;32m    290\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[39m=\u001b[39mbbox, mask\u001b[39m=\u001b[39mmask, rows\u001b[39m=\u001b[39mrows, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown engine \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/io/file.py:315\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     reader \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39mopen\n\u001b[1;32m    314\u001b[0m \u001b[39mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mwith\u001b[39;00m reader(path_or_bytes, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m features:\n\u001b[1;32m    316\u001b[0m         crs \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mcrs_wkt\n\u001b[1;32m    317\u001b[0m         \u001b[39m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[39m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[39m=\u001b[39m Collection(\n\u001b[1;32m    293\u001b[0m         path,\n\u001b[1;32m    294\u001b[0m         mode,\n\u001b[1;32m    295\u001b[0m         driver\u001b[39m=\u001b[39mdriver,\n\u001b[1;32m    296\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m    297\u001b[0m         layer\u001b[39m=\u001b[39mlayer,\n\u001b[1;32m    298\u001b[0m         enabled_drivers\u001b[39m=\u001b[39menabled_drivers,\n\u001b[1;32m    299\u001b[0m         allow_unsupported_drivers\u001b[39m=\u001b[39mallow_unsupported_drivers,\n\u001b[1;32m    300\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    301\u001b[0m     )\n\u001b[1;32m    302\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[39m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mstart(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    244\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: Data Scrapping/Data/district_borders.json: No such file or directory"
     ]
    }
   ],
   "source": [
    "district_borders = gpd.read_file('Data Scrapping/Data/district_borders.json')\n",
    "df['geometry'] = df.apply(lambda row: Point(row['long'], row['lat']), axis=1)\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "joined = gpd.sjoin(gdf, district_borders, how=\"left\", op='within')\n",
    "df['district'] = df['district'].fillna(joined['NOMI'])\n",
    "df.drop(columns=['geometry'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['type'].str.lower()\n",
    "\n",
    "corrections = {\n",
    "    'квартира': 'квартира',\n",
    "    'квартира': 'квартира',\n",
    "    'частный дом': 'частный',\n",
    "    'земля': 'частный',\n",
    "    'участок': 'частный',\n",
    "    'евро дом': 'частный',\n",
    "    'дом': 'частный',\n",
    "    'частный дом на продажу':'частный',\n",
    "    'квартира во вторичке на продажу': 'квартира',\n",
    "    'квартира в новостройке на продажу': 'квартира',\n",
    "    'дача на продажу': 'частный',\n",
    "}                                       \n",
    "\n",
    "df['type'].replace(corrections, inplace=True)\n",
    "\n",
    "allowed_categories = corrections.values()\n",
    "df = df[df['type'].isin(allowed_categories)]\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['building_type'] = df['building_type'].str.lower()\n",
    "\n",
    "corrections = {\n",
    "    'Новострой': 'первичный',\n",
    "    'Вторичный': 'вторичный',\n",
    "    'Вторичка': 'вторичный',\n",
    "    'Вторичный рынок': 'вторичный',\n",
    "    'Новостройки': 'первичный',\n",
    "    'Первичный': 'первичный',\n",
    "    'вторичный': 'вторичный',\n",
    "    'Новостройка': 'первичный',\n",
    "    'первичный': 'первичный',\n",
    "    'первычный': 'первичный',\n",
    "    'Вторичний':  'вторичный',\n",
    "    'торичный': 'вторичный',\n",
    "    'Вторичные': 'вторичный',\n",
    "    'Вторичный': 'вторичный',\n",
    "    'вторичный рынок': 'вторичный',\n",
    "    'новостройка': 'первичный',\n",
    "    'новостройки': 'первичный',\n",
    "    'новострой': 'первичный',\n",
    "    'вторичка': 'вторичный',\n",
    "}\n",
    "\n",
    "df['building_type'].replace(corrections, inplace=True)\n",
    "allowed_categories = corrections.values()\n",
    "df = df[df['building_type'].isin(allowed_categories)]\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['renovation'] = df['renovation'].str.lower()\n",
    "\n",
    "corrections = {\n",
    "    'евро ремонт': 'евроремонт',\n",
    "    'квро ремонт': 'евроремонт',\n",
    "    'евро ремонт': 'евроремонт',\n",
    "    'с ремонтом': 'средний ремонт',\n",
    "    'требуется ремонт': 'нужен ремонт',\n",
    "    'требует ремонта': 'нужен ремонт',\n",
    "    'средняя': 'средний ремонт',\n",
    "    'среднее состояние': 'средний ремонт',\n",
    "    'требует ремонта': 'нужен ремонт',\n",
    "    'незаконченный евроремонт': 'нужен ремонт',\n",
    "    'требует ремонта':  'нужен ремонт',\n",
    "    'дизайнерский': 'евроремонт',\n",
    "    'не требуется': 'средний ремонт',\n",
    "    'косметический': 'евроремонт',\n",
    "    'черновая отделка': 'нужен ремонт',\n",
    "    'коробка': 'нужен ремонт',\n",
    "    'без ремонта': 'нужен ремонт',\n",
    "    'капитальный ремонт': 'евроремонт',\n",
    "}\n",
    "\n",
    "df['renovation'].replace(corrections, inplace=True)\n",
    "allowed_categories = corrections.values()\n",
    "df = df[df['renovation'].isin(allowed_categories)]\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'district' column and count the number of rows in each group\n",
    "district_counts = df.groupby('district').size()\n",
    "\n",
    "# Display the count of rows in each district\n",
    "district_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_excel('Data Scrapping/Data/Map_Data.xlsx')\n",
    "categories_to_keep = ['Школа', 'Супермаркет', 'Магазин', 'Частная школа', 'Средняя школа', 'Начальная школа',\n",
    "                      'Международная школа', 'Торговый центр', 'Продовольственный магазин',\n",
    "                      'Магазин шаговой доступности', 'Супермаркет низких цен', 'Ресторан', 'фастфуд',\n",
    "                      'Узбекская кухня','Кафе','Суши','Турецкая кухня','Гамбургеры','Корейская кухня','Японская кухня','Еда на вынос','Доставка готовой еды','Парк']\n",
    "\n",
    "df_map = df_map[df_map['category'].isin(categories_to_keep)]\n",
    "\n",
    "corrections = {\n",
    "    'Магазин': 'grocery',\n",
    "    'Супермаркет': 'grocery',\n",
    "    'Продовольственный магазин': 'grocery',\n",
    "    'Магазин шаговой доступности': 'grocery',\n",
    "    'Супермаркет низких цен': 'grocery',\n",
    "    'Рынок': 'grocery',\n",
    "    'Начальная школа': 'school',\n",
    "    'Частная школа': 'school',\n",
    "    'Средняя школа': 'school',\n",
    "    'Школа': 'school',\n",
    "    'Международная школа': 'school',\n",
    "    'Торговый центр': 'mall',\n",
    "    'Парк': 'park',\n",
    "    'Ресторан':'food', \n",
    "    'фастфуд':'food',\n",
    "    'Узбекская кухня':'food',\n",
    "    'Кафе':'food',\n",
    "    'Суши':'food',\n",
    "    'Турецкая кухня':'food',\n",
    "    'Гамбургеры':'food',\n",
    "    'Корейская кухня':'food',\n",
    "    'Японская кухня':'food',\n",
    "    'Еда на вынос':'food',\n",
    "    'Доставка готовой еды':'food',\n",
    "    'Парк': 'park'\n",
    "}\n",
    "\n",
    "df_map['category'].replace(corrections, inplace=True)\n",
    "\n",
    "df_map.dropna(subset=['category', 'lat', 'long'], inplace=True)\n",
    "\n",
    "df_map.drop_duplicates(subset=['category', 'lat', 'long'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    mode_value = df[column].mode()[0]\n",
    "    df[column] = df[column].fillna(mode_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column, threshold):\n",
    "    # Convert column to numeric type if necessary\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean_val = df[column].mean()\n",
    "    std_val = df[column].std()\n",
    "    \n",
    "    # Calculate lower and upper bounds for outliers\n",
    "    lower_bound = mean_val - threshold * std_val\n",
    "    upper_bound = mean_val + threshold * std_val\n",
    "    \n",
    "    # Remove outliers\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = remove_outliers(df, 'price', 3)\n",
    "df = remove_outliers(df, 'num_of_rooms', 3)\n",
    "df = remove_outliers(df, 'area', 3)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['renovation',\t'district', 'area',\t'num_of_rooms', 'type', 'building_type', 'price']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_drop(df, column_name):\n",
    "    one_hot_encoded = pd.get_dummies(df[column_name], prefix=column_name)\n",
    "    one_hot_encoded = one_hot_encoded.astype(int)\n",
    "    \n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    \n",
    "    df.drop(column_name, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "columns_to_process = ['district', 'renovation', 'type', 'building_type']\n",
    "for column in columns_to_process:\n",
    "    df = encode_and_drop(df, column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = \"..\\\\Data\\\\Cleaned_Combined.xlsx\"\n",
    "existing_data = pd.read_excel(excel_file_path)\n",
    "combined_data = pd.concat([existing_data, df])\n",
    "combined_data.drop_duplicates(keep='first', inplace=True)\n",
    "combined_data.to_excel(excel_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
